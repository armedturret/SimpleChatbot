{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitprogramdatavirtualenve74f98f206a144e9930fc7ad4501d43a",
   "display_name": "Python 3.7.4 64-bit ('ProgramData': virtualenv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#uses movie conversations and movie lines to create a (prompts, responses) tuple\n",
    "def create_data():\n",
    "    dialouge = open('./movie_lines.txt').read()\n",
    "    conversations = open('./movie_conversations.txt').read()\n",
    "    dialogue_data = {} #key val map with move linenumas the key and dialouge as the val\n",
    "\n",
    "    prompts, responses = [], []\n",
    "\n",
    "    #process the dialouge first\n",
    "    for l in dialouge.split('\\n'):\n",
    "        line = l.split(' +++$+++ ')\n",
    "        if not len(line) == 5: #skip if too short\n",
    "            continue\n",
    "        #treate puncation as sepereate by spacing them out and then removing all but the recognized characters\n",
    "        dialogue_data[(line[2] + line[0])] = '<start> '+re.sub(r\"[^a-zA-Z?.!'']+\", \" \", re.sub(r'[\" \"]+', \" \", re.sub(r\"([?.!])\", r\" \\1 \", line[4]))).strip()+' <end>'\n",
    "\n",
    "    #use the conversations file to assemble conversations\n",
    "    for l in conversations.split('\\n'):\n",
    "        line = l.split(' +++$+++ ')\n",
    "\n",
    "        if not len(line) == 4: #skip if too short\n",
    "            continue\n",
    "        #parse the last element as a list\n",
    "        lines = ast.literal_eval(line[3])\n",
    "        for i in range(1, len(lines)):\n",
    "            #assemble the lists\n",
    "            prompts.append(dialogue_data[line[2] + lines[i-1]])\n",
    "            responses.append(dialogue_data[line[2] + lines[i]])\n",
    "\n",
    "    return prompts, responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the data set creation function\n",
    "original_prompts, original_responses = create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<start> Can we make this quick ? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break up on the quad . Again . <end> <start> Well I thought we'd start with pronunciation if that's okay with you . <end>\n"
     ]
    }
   ],
   "source": [
    "#print an example prompt/response\n",
    "print(original_prompts[0], original_responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the tokenizer for the sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# handle everything including punctuation\n",
    "c_tokenizer = Tokenizer(filters='', oov_token='<OOV>')\n",
    "# fit on all data\n",
    "c_tokenizer.fit_on_texts(original_prompts + original_responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and pad the sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "data_x = c_tokenizer.texts_to_sequences(original_prompts)\n",
    "data_x = pad_sequences(data_x, padding='post')\n",
    "\n",
    "data_y = c_tokenizer.texts_to_sequences(original_responses)\n",
    "data_y = pad_sequences(data_y, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(221616, 376)\n"
     ]
    }
   ],
   "source": [
    "print(data_x.shape, data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab some variables to be used for training\n",
    "# add 1 char for padding\n",
    "vocab_size = len(c_tokenizer.word_index) + 1\n",
    "\n",
    "#specify some values for the model\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "BUFFER_SIZE = len(data_x)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(data_x)//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a tensorflow dataset for training purposes\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data_x, data_y)).shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}